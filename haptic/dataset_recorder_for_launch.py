import os
import rclpy
from rclpy.node import Node
from rclpy.serialization import serialize_message
from lbr_fri_idl.msg import LBRJointPositionCommand, LBRState
from sensor_msgs.msg import JointState
from tutorial_interfaces.msg import Array3, Cloud
from std_msgs.msg import Float32
import rosbag2_py
from datetime import datetime
from collections import deque
import json
import csv
import threading
import select
import sys
import termios
import tty

def open_writer(writer, abs_dir_path):
    storage_options = rosbag2_py._storage.StorageOptions(
        uri=abs_dir_path,
        storage_id='sqlite3')
    converter_options = rosbag2_py._storage.ConverterOptions('', '')
    writer.open(storage_options, converter_options)

class LaunchControlledRecorder(Node):
    """é€šè¿‡Launchå¯åŠ¨ï¼Œç­‰å¾…ç”¨æˆ·è¾“å…¥æ‰å¼€å§‹è®°å½•çš„æ•°æ®è®°å½•å™¨"""
    def __init__(self):
        super().__init__('launch_controlled_recorder')
        
        # æ•°æ®è®°å½•çŠ¶æ€
        self.recording_active = False
        self.recorder = None
        
        # æ˜¾ç¤ºå¯åŠ¨ä¿¡æ¯git 
        self.get_logger().info("=" * 60)
        self.get_logger().info("ğŸš€ æ•°æ®é‡‡é›†å™¨å·²å¯åŠ¨å¹¶ç­‰å¾…æŒ‡ä»¤")
        self.get_logger().info("=" * 60)
        self.get_logger().info("ğŸ“ æŒ‡ä»¤è¯´æ˜:")
        self.get_logger().info("   è¾“å…¥ '1' + Enter: å¼€å§‹æ•°æ®é‡‡é›†")
        self.get_logger().info("   è¾“å…¥ '2' + Enter: åœæ­¢æ•°æ®é‡‡é›†")
        self.get_logger().info("   è¾“å…¥ 'q' + Enter: é€€å‡ºç¨‹åº")
        self.get_logger().info("=" * 60)
        self.get_logger().info("â³ ç­‰å¾…æ‚¨çš„æŒ‡ä»¤...")
        
        # å¯åŠ¨è¾“å…¥ç›‘å¬çº¿ç¨‹
        self.input_thread = threading.Thread(target=self.input_listener, daemon=True)
        self.input_thread.start()
        
        # å®šæœŸæ£€æŸ¥çŠ¶æ€
        self.timer = self.create_timer(1.0, self.status_check)
    
    def input_listener(self):
        """ç›‘å¬ç”¨æˆ·è¾“å…¥çš„çº¿ç¨‹"""
        while rclpy.ok():
            try:
                user_input = input().strip()
                
                if user_input == '1':
                    if not self.recording_active:
                        self.start_recording()
                    else:
                        self.get_logger().warn("âŒ æ•°æ®é‡‡é›†å·²åœ¨è¿›è¡Œä¸­")
                        
                elif user_input == '2':
                    if self.recording_active:
                        self.stop_recording()
                    else:
                        self.get_logger().warn("âŒ æ•°æ®é‡‡é›†æœªåœ¨è¿›è¡Œä¸­")
                        
                elif user_input.lower() == 'q':
                    self.get_logger().info("ğŸ›‘ æ­£åœ¨é€€å‡ºç¨‹åº...")
                    if self.recording_active:
                        self.stop_recording()
                    rclpy.shutdown()
                    break
                    
                else:
                    self.get_logger().info("â“ æ— æ•ˆæŒ‡ä»¤ã€‚è¯·è¾“å…¥ '1'(å¼€å§‹), '2'(åœæ­¢), æˆ– 'q'(é€€å‡º)")
                    
            except EOFError:
                # å¤„ç†Ctrl+D
                break
            except KeyboardInterrupt:
                # å¤„ç†Ctrl+C
                self.get_logger().info("ğŸ›‘ æ”¶åˆ°ä¸­æ–­ä¿¡å·ï¼Œæ­£åœ¨é€€å‡º...")
                if self.recording_active:
                    self.stop_recording()
                rclpy.shutdown()
                break
    
    def start_recording(self):
        """å¼€å§‹æ•°æ®è®°å½•"""
        try:
            self.get_logger().info("ğŸŸ¢ å¼€å§‹å¯åŠ¨æ•°æ®é‡‡é›†å™¨...")
            
            # åˆ›å»ºé«˜çº§åŒæ­¥è®°å½•å™¨
            self.recorder = AdvancedSyncBagRecorder(sync_window_ms=50, parent_node=self)
            self.recording_active = True
            
            self.get_logger().info("âœ… æ•°æ®é‡‡é›†å·²å¼€å§‹!")
            self.get_logger().info(f"ğŸ“ æ•°æ®ä¿å­˜è·¯å¾„: {self.recorder.unique_dir}")
            self.get_logger().info("ğŸ’¡ è¾“å…¥ '2' åœæ­¢é‡‡é›†")
            
        except Exception as e:
            error_msg = str(e)
            if "already exists" in error_msg:
                self.get_logger().warn("âš ï¸ ç›®å½•å·²å­˜åœ¨ï¼Œæ­£åœ¨åˆ›å»ºæ–°çš„æ—¶é—´æˆ³ç›®å½•...")
                try:
                    # é‡æ–°å°è¯•åˆ›å»ºè®°å½•å™¨ï¼ˆä¼šç”Ÿæˆæ–°çš„æ—¶é—´æˆ³ï¼‰
                    import time
                    time.sleep(1)  # ç­‰å¾…1ç§’ç¡®ä¿æ—¶é—´æˆ³ä¸åŒ
                    self.recorder = AdvancedSyncBagRecorder(sync_window_ms=50, parent_node=self)
                    self.recording_active = True
                    self.get_logger().info("âœ… æ•°æ®é‡‡é›†å·²å¼€å§‹!")
                    self.get_logger().info(f"ğŸ“ æ•°æ®ä¿å­˜è·¯å¾„: {self.recorder.unique_dir}")
                    self.get_logger().info("ğŸ’¡ è¾“å…¥ '2' åœæ­¢é‡‡é›†")
                except Exception as e2:
                    self.get_logger().error(f"âŒ é‡è¯•åä»ç„¶å¤±è´¥: {str(e2)}")
                    self.recording_active = False
            else:
                self.get_logger().error(f"âŒ å¯åŠ¨æ•°æ®é‡‡é›†å¤±è´¥: {error_msg}")
                self.recording_active = False
    
    def stop_recording(self):
        """åœæ­¢æ•°æ®è®°å½•"""
        try:
            self.get_logger().info("ğŸŸ¡ æ­£åœ¨åœæ­¢æ•°æ®é‡‡é›†...")
            
            if self.recorder:
                # ç”Ÿæˆåˆ†ææŠ¥å‘Š
                self.recorder.generate_analysis_report()
                
                # æ¸…ç†èµ„æº
                self.recorder.cleanup()
                
                self.get_logger().info("âœ… æ•°æ®é‡‡é›†å·²åœæ­¢!")
                self.get_logger().info(f"ğŸ“ æ•°æ®å·²ä¿å­˜åˆ°: {self.recorder.unique_dir}")
                self.get_logger().info("ğŸ’¡ è¾“å…¥ '1' é‡æ–°å¼€å§‹é‡‡é›†")
                
                self.recorder = None
            
            self.recording_active = False
            
        except Exception as e:
            self.get_logger().error(f"âŒ åœæ­¢æ•°æ®é‡‡é›†å¤±è´¥: {str(e)}")
    
    def status_check(self):
        """å®šæœŸçŠ¶æ€æ£€æŸ¥"""
        if self.recording_active and self.recorder:
            # æ˜¾ç¤ºç®€å•çš„çŠ¶æ€ä¿¡æ¯
            if hasattr(self.recorder, 'sync_group_counter'):
                count = self.recorder.sync_group_counter
                if count > 0 and count % 100 == 0:
                    self.get_logger().info(f"ğŸ“Š å·²é‡‡é›† {count} ç»„åŒæ­¥æ•°æ®")


class AdvancedSyncBagRecorder:
    """æ”¹è¿›çš„åŒæ­¥æ•°æ®è®°å½•å™¨ï¼Œé€‚é…Launchæ¨¡å¼"""
    def __init__(self, sync_window_ms=50, parent_node=None):
        self.parent_node = parent_node
        self.writer = rosbag2_py.SequentialWriter()
        self.sync_window_ns = sync_window_ms * 1e6
        
        # ä½¿ç”¨ç¼“å†²åŒºå­˜å‚¨å¤šä¸ªæ¶ˆæ¯ï¼Œç”¨äºæ—¶é—´åŒæ­¥
        self.msg_buffers = {}
        self.buffer_size = 100
        
        # åˆ›å»ºå”¯ä¸€ç›®å½•ç»“æ„
        current_workspace_path = os.getcwd()
        base_dir = os.path.join(current_workspace_path, 'training_data')
        
        # ç”Ÿæˆå”¯ä¸€ç›®å½•åï¼Œé¿å…å†²çª
        unique_dir_name = self.generate_unique_dirname()
        self.unique_dir = os.path.join(base_dir, 'launch_recorder', unique_dir_name)
        
        # ç¡®ä¿ç›®å½•ä¸å­˜åœ¨ï¼Œå¦‚æœå­˜åœ¨åˆ™ç”Ÿæˆæ–°çš„
        while os.path.exists(self.unique_dir):
            unique_dir_name = self.generate_unique_dirname()
            self.unique_dir = os.path.join(base_dir, 'launch_recorder', unique_dir_name)
        
        # åˆ›å»ºç›®å½•ç»“æ„
        os.makedirs(self.unique_dir, exist_ok=True)
        
        # åˆ›å»ºå­ç›®å½•
        self.rosbag_dir = os.path.join(self.unique_dir, 'rosbag')
        self.raw_data_dir = os.path.join(self.unique_dir, 'raw_data')
        self.analysis_dir = os.path.join(self.unique_dir, 'analysis')
        
        os.makedirs(self.rosbag_dir, exist_ok=True)
        os.makedirs(self.raw_data_dir, exist_ok=True)
        os.makedirs(self.analysis_dir, exist_ok=True)
        
        # åˆå§‹åŒ–rosbagå†™å…¥å™¨
        open_writer(self.writer, self.rosbag_dir)
        
        # è¯é¢˜ç±»å‹å®šä¹‰
        self.topic_types = {
            # æœºå™¨äººç›¸å…³è¯é¢˜
            '/lbr/command/joint_position': 'lbr_fri_idl/msg/LBRJointPositionCommand',
            '/lbr/state': 'lbr_fri_idl/msg/LBRState',
            '/lbr/joint_states': 'sensor_msgs/msg/JointState',
            
            # Tac3Dä¼ æ„Ÿå™¨è¯é¢˜
            '/positions_r': 'tutorial_interfaces/msg/Cloud',
            '/displacements_r': 'tutorial_interfaces/msg/Cloud',
            '/forces_r': 'tutorial_interfaces/msg/Array3',
            '/resultant_force_r': 'tutorial_interfaces/msg/Cloud',
            '/resultant_moment_r': 'tutorial_interfaces/msg/Cloud',
            '/index_r': 'std_msgs/msg/Float32',
            
            '/positions_l': 'tutorial_interfaces/msg/Cloud',
            '/displacements_l': 'tutorial_interfaces/msg/Cloud',
            '/forces_l': 'tutorial_interfaces/msg/Array3',
            '/resultant_force_l': 'tutorial_interfaces/msg/Cloud',
            '/resultant_moment_l': 'tutorial_interfaces/msg/Cloud',
            '/index_l': 'std_msgs/msg/Float32'
        }
        
        # åˆ›å»ºåŸå§‹æ•°æ®è®°å½•æ–‡ä»¶
        self.raw_data_files = {}
        self.timing_file = open(os.path.join(self.analysis_dir, 'timing_analysis.csv'), 'w', newline='')
        self.timing_writer = csv.writer(self.timing_file)
        self.timing_writer.writerow([
            'timestamp', 'topic_name', 'receive_time', 'header_time', 
            'sync_group_id', 'time_diff_from_sync_target', 'data_summary'
        ])
        
        # åŒæ­¥ç»Ÿè®¡æ–‡ä»¶
        self.sync_stats_file = open(os.path.join(self.analysis_dir, 'sync_statistics.csv'), 'w', newline='')
        self.sync_stats_writer = csv.writer(self.sync_stats_file)
        self.sync_stats_writer.writerow([
            'sync_group_id', 'sync_target_time', 'max_time_diff_ms', 
            'num_topics_synced', 'sync_quality', 'timestamp'
        ])
        
        # çº¿ç¨‹é”å’Œè®¡æ•°å™¨
        self.file_lock = threading.Lock()
        self.sync_group_counter = 0
        
        # åˆå§‹åŒ–æ¶ˆæ¯ç¼“å†²åŒºå’Œè®¢é˜…å™¨
        self.setup_subscribers()
        
        # å¯åŠ¨åŒæ­¥å®šæ—¶å™¨
        if self.parent_node:
            self.timer = self.parent_node.create_timer(0.02, self.sync_and_write)
    
    def setup_subscribers(self):
        """è®¾ç½®è®¢é˜…å™¨å’Œæ•°æ®æ–‡ä»¶"""
        # åˆå§‹åŒ–æ¶ˆæ¯ç¼“å†²åŒºå’ŒåŸå§‹æ•°æ®æ–‡ä»¶
        for topic_name in self.topic_types.keys():
            self.msg_buffers[topic_name] = []
            
            # ä¸ºæ¯ä¸ªè¯é¢˜åˆ›å»ºåŸå§‹æ•°æ®è®°å½•æ–‡ä»¶
            safe_topic_name = topic_name.replace('/', '_')
            raw_file_path = os.path.join(self.raw_data_dir, f'{safe_topic_name}_raw.csv')
            self.raw_data_files[topic_name] = open(raw_file_path, 'w', newline='')
            
            # åˆ›å»ºCSVå†™å…¥å™¨å¹¶å†™å…¥å¤´éƒ¨
            writer = csv.writer(self.raw_data_files[topic_name])
            if 'Array3' in self.topic_types[topic_name]:
                writer.writerow(['timestamp', 'receive_time', 'header_time', 'x', 'y', 'z'])
            elif 'Cloud' in self.topic_types[topic_name]:
                writer.writerow(['timestamp', 'receive_time', 'header_time', 'num_points', 'sample_points'])
            elif 'Float32' in self.topic_types[topic_name]:
                writer.writerow(['timestamp', 'receive_time', 'header_time', 'value'])
            else:
                writer.writerow(['timestamp', 'receive_time', 'header_time', 'data_summary'])

        self._subscriptions = []

        topic_id = 0
        for topic_name, topic_type in self.topic_types.items():
            topic_info = rosbag2_py._storage.TopicMetadata(
                id=topic_id,
                name=topic_name,
                type=topic_type,
                serialization_format='cdr')
            self.writer.create_topic(topic_info)
            topic_id += 1

            msg_type = eval(topic_type.split('/')[2])

            if self.parent_node:
                self._subscriptions.append(self.parent_node.create_subscription(
                    msg_type,
                    topic_name,
                    self.buffered_callback(topic_name),
                    10
                ))
    
    def buffered_callback(self, topic_name):
        """åˆ›å»ºå¸¦ç¼“å†²çš„å›è°ƒå‡½æ•°"""
        def callback(msg):
            receive_time = self.parent_node.get_clock().now().nanoseconds
            
            # è·å–æ¶ˆæ¯æ—¶é—´æˆ³
            if hasattr(msg, 'header') and hasattr(msg.header, 'stamp'):
                msg_time = msg.header.stamp.sec * 1e9 + msg.header.stamp.nanosec
                header_time = msg_time
            else:
                msg_time = receive_time
                header_time = None
            
            # æ·»åŠ åˆ°ç¼“å†²åŒº
            msg_entry = {
                'msg': msg,
                'timestamp': msg_time,
                'receive_time': receive_time,
                'header_time': header_time
            }
            
            self.msg_buffers[topic_name].append(msg_entry)
            
            # ä¿æŒç¼“å†²åŒºå¤§å°
            if len(self.msg_buffers[topic_name]) > self.buffer_size:
                self.msg_buffers[topic_name].pop(0)
            
            # è®°å½•åŸå§‹æ•°æ®åˆ°CSVæ–‡ä»¶
            self.record_raw_data(topic_name, msg, receive_time, header_time)
                
        return callback
    
    def record_raw_data(self, topic_name, msg, receive_time, header_time):
        """è®°å½•åŸå§‹æ•°æ®åˆ°CSVæ–‡ä»¶"""
        try:
            with self.file_lock:
                writer = csv.writer(self.raw_data_files[topic_name])
                timestamp = datetime.now().isoformat()
                
                if hasattr(msg, 'x') and hasattr(msg, 'y') and hasattr(msg, 'z'):
                    writer.writerow([timestamp, receive_time, header_time, msg.x, msg.y, msg.z])
                elif hasattr(msg, 'row1') and hasattr(msg, 'row2') and hasattr(msg, 'row3'):
                    num_points = len(msg.row1) if msg.row1 else 0
                    sample_points = f"[{msg.row1[:3] if msg.row1 else []}...]" if num_points > 0 else "[]"
                    writer.writerow([timestamp, receive_time, header_time, num_points, sample_points])
                elif hasattr(msg, 'data'):
                    writer.writerow([timestamp, receive_time, header_time, msg.data])
                else:
                    data_summary = str(msg)[:100] + "..." if len(str(msg)) > 100 else str(msg)
                    writer.writerow([timestamp, receive_time, header_time, data_summary])
                
                self.raw_data_files[topic_name].flush()
        except Exception as e:
            if self.parent_node:
                self.parent_node.get_logger().error(f"è®°å½•åŸå§‹æ•°æ®å¤±è´¥ ({topic_name}): {str(e)}")
    
    def sync_and_write(self):
        """åŸºäºæ—¶é—´çª—å£è¿›è¡Œæ¶ˆæ¯åŒæ­¥å¹¶å†™å…¥"""
        # æ‰¾åˆ°æœ€æ–°çš„å…±åŒæ—¶é—´ç‚¹
        latest_times = {}
        for topic_name, buffer in self.msg_buffers.items():
            if buffer:
                latest_times[topic_name] = buffer[-1]['timestamp']
        
        if len(latest_times) < len(self.topic_types):
            return  # è¿˜æ²¡æœ‰æ‰€æœ‰è¯é¢˜çš„æ•°æ®
        
        # æ‰¾åˆ°æ‰€æœ‰è¯é¢˜ä¸­æœ€æ—©çš„æœ€æ–°æ—¶é—´æˆ³ä½œä¸ºåŒæ­¥ç›®æ ‡
        sync_target = min(latest_times.values())
        
        # ä¸ºæ¯ä¸ªè¯é¢˜æ‰¾åˆ°æœ€æ¥è¿‘åŒæ­¥ç›®æ ‡çš„æ¶ˆæ¯
        synced_msgs = {}
        max_time_diff = 0
        timing_records = []
        
        for topic_name, buffer in self.msg_buffers.items():
            best_msg = None
            min_diff = float('inf')
            
            for msg_entry in reversed(buffer):
                time_diff = abs(msg_entry['timestamp'] - sync_target)
                if time_diff < min_diff:
                    min_diff = time_diff
                    best_msg = msg_entry
                    
                if time_diff > self.sync_window_ns:
                    break
            
            if best_msg and min_diff <= self.sync_window_ns:
                synced_msgs[topic_name] = best_msg
                max_time_diff = max(max_time_diff, min_diff)
                
                data_summary = self.get_data_summary(best_msg['msg'])
                timing_records.append({
                    'topic_name': topic_name,
                    'receive_time': best_msg['receive_time'],
                    'header_time': best_msg['header_time'],
                    'time_diff_from_sync_target': min_diff / 1e6,
                    'data_summary': data_summary
                })
        
        # åªæœ‰å½“æ‰€æœ‰è¯é¢˜éƒ½æ‰¾åˆ°åŒæ­¥æ¶ˆæ¯æ—¶æ‰å†™å…¥
        if len(synced_msgs) == len(self.topic_types):
            self.sync_group_counter += 1
            
            # å†™å…¥åŒæ­¥çš„rosbagæ•°æ®
            for topic_name, msg_entry in synced_msgs.items():
                self.writer.write(
                    topic_name,
                    serialize_message(msg_entry['msg']),
                    msg_entry['timestamp'])
            
            # è®°å½•æ—¶é—´åˆ†ææ•°æ®
            self.record_timing_analysis(timing_records, sync_target, max_time_diff)
    
    def get_data_summary(self, msg):
        """è·å–æ¶ˆæ¯æ•°æ®æ‘˜è¦"""
        if hasattr(msg, 'x') and hasattr(msg, 'y') and hasattr(msg, 'z'):
            return f"Array3({msg.x:.3f}, {msg.y:.3f}, {msg.z:.3f})"
        elif hasattr(msg, 'row1') and hasattr(msg, 'row2') and hasattr(msg, 'row3'):
            num_points = len(msg.row1) if msg.row1 else 0
            return f"Cloud({num_points} points)"
        elif hasattr(msg, 'data'):
            return f"Float32({msg.data:.6f})"
        else:
            return str(type(msg).__name__)
    
    def record_timing_analysis(self, timing_records, sync_target, max_time_diff):
        """è®°å½•æ—¶é—´åˆ†ææ•°æ®"""
        try:
            with self.file_lock:
                timestamp = datetime.now().isoformat()
                
                for record in timing_records:
                    self.timing_writer.writerow([
                        timestamp,
                        record['topic_name'],
                        record['receive_time'],
                        record['header_time'],
                        self.sync_group_counter,
                        record['time_diff_from_sync_target'],
                        record['data_summary']
                    ])
                
                sync_quality = "excellent" if max_time_diff / 1e6 < 5 else \
                              "good" if max_time_diff / 1e6 < 10 else \
                              "fair" if max_time_diff / 1e6 < 20 else "poor"
                
                self.sync_stats_writer.writerow([
                    self.sync_group_counter,
                    sync_target,
                    max_time_diff / 1e6,
                    len(timing_records),
                    sync_quality,
                    timestamp
                ])
                
                self.timing_file.flush()
                self.sync_stats_file.flush()
                
        except Exception as e:
            if self.parent_node:
                self.parent_node.get_logger().error(f"è®°å½•æ—¶é—´åˆ†æå¤±è´¥: {str(e)}")
    
    def generate_analysis_report(self):
        """ç”Ÿæˆæ•°æ®åˆ†ææŠ¥å‘Š"""
        try:
            report_path = os.path.join(self.analysis_dir, 'analysis_report.json')
            
            report = {
                'session_info': {
                    'end_time': datetime.now().isoformat(),
                    'unique_dir': self.unique_dir,
                    'sync_window_ms': self.sync_window_ns / 1e6,
                    'buffer_size': self.buffer_size,
                    'total_sync_groups': self.sync_group_counter
                },
                'topics': {},
                'file_structure': {
                    'rosbag_dir': self.rosbag_dir,
                    'raw_data_dir': self.raw_data_dir,
                    'analysis_dir': self.analysis_dir,
                    'timing_analysis_file': os.path.join(self.analysis_dir, 'timing_analysis.csv'),
                    'sync_statistics_file': os.path.join(self.analysis_dir, 'sync_statistics.csv')
                }
            }
            
            for topic_name, topic_type in self.topic_types.items():
                safe_topic_name = topic_name.replace('/', '_')
                report['topics'][topic_name] = {
                    'type': topic_type,
                    'raw_data_file': os.path.join(self.raw_data_dir, f'{safe_topic_name}_raw.csv'),
                    'buffer_current_size': len(self.msg_buffers.get(topic_name, [])),
                    'buffer_max_size': self.buffer_size
                }
            
            with open(report_path, 'w', encoding='utf-8') as f:
                json.dump(report, f, indent=2, ensure_ascii=False)
            
            if self.parent_node:
                self.parent_node.get_logger().info(f"ğŸ“‹ åˆ†ææŠ¥å‘Šå·²ç”Ÿæˆ: {report_path}")
            
        except Exception as e:
            if self.parent_node:
                self.parent_node.get_logger().error(f"ç”Ÿæˆåˆ†ææŠ¥å‘Šå¤±è´¥: {str(e)}")
    
    def cleanup(self):
        """æ¸…ç†èµ„æº"""
        try:
            for file_handle in self.raw_data_files.values():
                if not file_handle.closed:
                    file_handle.close()
            
            if hasattr(self, 'timing_file') and not self.timing_file.closed:
                self.timing_file.close()
            
            if hasattr(self, 'sync_stats_file') and not self.sync_stats_file.closed:
                self.sync_stats_file.close()
                
        except Exception as e:
            if self.parent_node:
                self.parent_node.get_logger().error(f"æ¸…ç†èµ„æºæ—¶å‡ºé”™: {str(e)}")
    
    def generate_unique_dirname(self):
        """ç”Ÿæˆå”¯ä¸€çš„ç›®å½•å"""
        import time
        now = datetime.now()
        # ä½¿ç”¨æ›´ç²¾ç¡®çš„æ—¶é—´æˆ³ï¼ŒåŒ…å«å¾®ç§’
        return now.strftime('%Y%m%d_%H%M%S_%f')[:-3]  # å»æ‰æœ€å3ä½å¾®ç§’ï¼Œä¿ç•™æ¯«ç§’


def main(args=None):
    rclpy.init(args=args)
    
    # åˆ›å»ºLaunchæ§åˆ¶çš„è®°å½•å™¨
    recorder = LaunchControlledRecorder()
    
    try:
        rclpy.spin(recorder)
    except KeyboardInterrupt:
        recorder.get_logger().info("ğŸ›‘ æ”¶åˆ°é”®ç›˜ä¸­æ–­ä¿¡å·")
    finally:
        if recorder.recording_active:
            recorder.stop_recording()
        recorder.destroy_node()
        rclpy.shutdown()


if __name__ == '__main__':
    main()
